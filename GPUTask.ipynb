{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPUTask.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "gu9esdpRvNx-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Resources\n",
        "\n",
        "https://devblogs.nvidia.com/even-easier-introduction-cuda/\n",
        "\n",
        "https://developer.nvidia.com/cuda-downloads?target_os=Linux\n",
        "\n",
        "https://sites.google.com/site/5kk70gpu/matrixmul-example\n",
        "\n",
        "https://sites.google.com/site/5kk70gpu/installation\n",
        "\n",
        "https://sites.google.com/site/5kk70gpu/assignment-s/color-conversion\n"
      ]
    },
    {
      "metadata": {
        "id": "IsPzceRIu-7K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# NVIDIA and System checking"
      ]
    },
    {
      "metadata": {
        "id": "MDFs2fMtvkC9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Check GPU \n",
        "(2ways)"
      ]
    },
    {
      "metadata": {
        "id": "d2-fZfiAQ9Ja",
        "colab_type": "code",
        "outputId": "b456f8fd-7908-44b0-c591-fc1ba2e70a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#check gpu \n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "Ei4wp_W0vqXB",
        "colab_type": "code",
        "outputId": "a192577f-9b2d-4aba-9658-de26d73a3991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "#Show our GPU specificaion\n",
        "! nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Dec 14 12:44:00 2018       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    62W / 149W |    116MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lHM-gHeav2NE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Check OS"
      ]
    },
    {
      "metadata": {
        "id": "b-e8gY8iRE3m",
        "colab_type": "code",
        "outputId": "924bf53a-7ac7-46d9-ed6c-68ce2e1dd714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "#check operating system\n",
        "!uname -m && cat /etc/*release"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x86_64\n",
            "DISTRIB_ID=Ubuntu\n",
            "DISTRIB_RELEASE=18.04\n",
            "DISTRIB_CODENAME=bionic\n",
            "DISTRIB_DESCRIPTION=\"Ubuntu 18.04.1 LTS\"\n",
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"18.04.1 LTS (Bionic Beaver)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 18.04.1 LTS\"\n",
            "VERSION_ID=\"18.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=bionic\n",
            "UBUNTU_CODENAME=bionic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BdueYmROwAvw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Check gcc version"
      ]
    },
    {
      "metadata": {
        "id": "bztLySdHRWZi",
        "colab_type": "code",
        "outputId": "13b340c8-9aa0-4392-82ca-8e3f40267cc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "#check gcc version\n",
        "!gcc --version\n",
        "#cuda need gcc version 6 --> install version 6\n",
        "!apt-get install gcc-6\n",
        "!apt-get install g++-6"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gcc (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "gcc-6 is already the newest version (6.4.0-17ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "g++-6 is already the newest version (6.4.0-17ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EXRczq6ZwTra",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Nvidia Driver and Cuda toolkit installation "
      ]
    },
    {
      "metadata": {
        "id": "Y5s1-CI6WkRe",
        "colab_type": "code",
        "outputId": "5684a682-ee95-466e-94c3-076963b94d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "cell_type": "code",
      "source": [
        "!wget \"http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64/cuda-repo-ubuntu1704_9.1.85-1_amd64.deb\"\n",
        "!dpkg -i cuda-repo-ubuntu1704_9.1.85-1_amd64.deb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-14 12:49:57--  http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64/cuda-repo-ubuntu1704_9.1.85-1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 192.229.221.58, 2606:2800:233:ef6:15dd:1ece:1d50:1e1\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|192.229.221.58|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2830 (2.8K) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu1704_9.1.85-1_amd64.deb’\n",
            "\n",
            "\r          cuda-repo   0%[                    ]       0  --.-KB/s               \rcuda-repo-ubuntu170 100%[===================>]   2.76K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-12-14 12:49:57 (271 MB/s) - ‘cuda-repo-ubuntu1704_9.1.85-1_amd64.deb’ saved [2830/2830]\n",
            "\n",
            "(Reading database ... 111405 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1704_9.1.85-1_amd64.deb ...\n",
            "Unpacking cuda-repo-ubuntu1704 (9.1.85-1) over (9.1.85-1) ...\n",
            "Setting up cuda-repo-ubuntu1704 (9.1.85-1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QdX_mF9zW3uM",
        "colab_type": "code",
        "outputId": "5b5cee22-930c-4bb0-9a22-507407107e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install dirmngr\n",
        "!apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64/7fa2af80.pub"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "dirmngr is already the newest version (2.2.4-1ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n",
            "Executing: /tmp/apt-key-gpghome.kOeu68FNIR/gpg.1.sh --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64/7fa2af80.pub\n",
            "gpg: requesting key from 'http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64/7fa2af80.pub'\n",
            "gpg: key F60F4B3D7FA2AF80: \"cudatools <cudatools@nvidia.com>\" not changed\n",
            "gpg: Total number processed: 1\n",
            "gpg:              unchanged: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uwWAtiLgXQey",
        "colab_type": "code",
        "outputId": "27ed7a10-7cbc-4b29-8c43-c0b7b5e9ad72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install cuda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to developer.download\r                                                                               \rHit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r0% [Waiting for headers] [Connected to developer.download.nvidia.com (192.229.2\r0% [1 InRelease gpgv 21.3 kB] [Waiting for headers] [Connected to developer.dow\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 21.3 kB] [Waiting for headers] [Connected to developer.dow\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "\r                                                                               \r0% [1 InRelease gpgv 21.3 kB] [Waiting for headers] [Waiting for headers]\r                                                                         \rHit:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "\r                                                                         \r0% [1 InRelease gpgv 21.3 kB] [Waiting for headers]\r                                                   \r0% [Waiting for headers]\r0% [2 InRelease gpgv 83.2 kB] [Waiting for headers]\r                                                   \rIgn:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 83.2 kB] [Waiting for headers]\r                                                   \rIgn:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  InRelease\n",
            "\r                                                   \r0% [2 InRelease gpgv 83.2 kB]\r                             \r0% [Waiting for headers]\r0% [3 InRelease gpgv 242 kB] [Waiting for headers]\r                                                  \rHit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  Release\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cuda is already the newest version (9.2.148-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C0e_-e2yx1nR",
        "colab_type": "code",
        "outputId": "59d2b2bc-bfe5-4b1a-c6fe-0abae26f153e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "#Install CUDA Toolkit\n",
        "#!apt-get install nvidia-cuda-toolkit\n",
        "!nvcc --version   #CUDA files have the file extension .cu. and compile it with nvcc, the CUDA C++ compiler."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Tue_Jun_12_23:07:04_CDT_2018\n",
            "Cuda compilation tools, release 9.2, V9.2.148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZHu8RLgY3wi3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#linking cuda compiler to gcc 6\n",
        "!ln -s -f /usr/bin/gcc-6 /usr/local/cuda-9.2/bin/gcc\n",
        "!ln -s -f /usr/bin/g++-6 /usr/local/cuda-9.2/bin/g++"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yVjr32NsK1eI",
        "colab_type": "code",
        "outputId": "6d98779e-6a8c-440b-d230-8f0ac99451ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "#verify that the NVIDIA display driver is installed (unnecessary step)\n",
        "!lspci -v | grep -i nvidia"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lspci: Unable to load libkmod resources: error -12\r\n",
            "00:04.0 3D controller: NVIDIA Corporation GK210GL [Tesla K80] (rev a1)\r\n",
            "\tSubsystem: NVIDIA Corporation Device 106c\r\n",
            "\tKernel driver in use: nvidia\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LwDM5WZiyDWG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Test Cuda samples"
      ]
    },
    {
      "metadata": {
        "id": "Hf9ErMyD3YZ1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## browse cuda samples"
      ]
    },
    {
      "metadata": {
        "id": "vh1I5XfulaXa",
        "colab_type": "code",
        "outputId": "1d9cd2e1-b0ea-49fa-b038-3d6f21f65782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"*** Listing learning samples downloaded with cuda ***\")\n",
        "!ls /usr/local/cuda-9.2/samples\n",
        "\n",
        "print( \"\\n *** Listing vector add Hello world sample ***\")\n",
        "!ls /usr/local/cuda-9.2/samples/0_Simple/vectorAdd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** listing learning samples downloaded with cuda ***\n",
            "0_Simple     2_Graphics  4_Finance\t6_Advanced\t common    Makefile\n",
            "1_Utilities  3_Imaging\t 5_Simulations\t7_CUDALibraries  EULA.txt\n",
            "\n",
            " *** Listing vector add Hello world sample ***\n",
            "Makefile  NsightEclipse.xml  readme.txt  vectorAdd.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f3x4N6hNybjs",
        "colab_type": "code",
        "outputId": "e54f8b43-876f-4404-eb38-caad5459aaca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3417
        }
      },
      "cell_type": "code",
      "source": [
        "print( \"\\n *** Checking vectorAdd.cu ***\")\n",
        "!cat /usr/local/cuda-9.2/samples/0_Simple/vectorAdd/vectorAdd.cu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " *** Checking vectorAdd.cu ***\n",
            "/**\n",
            " * Copyright 1993-2015 NVIDIA Corporation.  All rights reserved.\n",
            " *\n",
            " * Please refer to the NVIDIA end user license agreement (EULA) associated\n",
            " * with this source code for terms and conditions that govern your use of\n",
            " * this software. Any use, reproduction, disclosure, or distribution of\n",
            " * this software and related documentation outside the terms of the EULA\n",
            " * is strictly prohibited.\n",
            " *\n",
            " */\n",
            "\n",
            "/**\n",
            " * Vector addition: C = A + B.\n",
            " *\n",
            " * This sample is a very basic sample that implements element by element\n",
            " * vector addition. It is the same as the sample illustrating Chapter 2\n",
            " * of the programming guide with some additions like error checking.\n",
            " */\n",
            "\n",
            "#include <stdio.h>\n",
            "\n",
            "// For the CUDA runtime routines (prefixed with \"cuda_\")\n",
            "#include <cuda_runtime.h>\n",
            "\n",
            "#include <helper_cuda.h>\n",
            "/**\n",
            " * CUDA Kernel Device code\n",
            " *\n",
            " * Computes the vector addition of A and B into C. The 3 vectors have the same\n",
            " * number of elements numElements.\n",
            " */\n",
            "__global__ void\n",
            "vectorAdd(const float *A, const float *B, float *C, int numElements)\n",
            "{\n",
            "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
            "\n",
            "    if (i < numElements)\n",
            "    {\n",
            "        C[i] = A[i] + B[i];\n",
            "    }\n",
            "}\n",
            "\n",
            "/**\n",
            " * Host main routine\n",
            " */\n",
            "int\n",
            "main(void)\n",
            "{\n",
            "    // Error code to check return values for CUDA calls\n",
            "    cudaError_t err = cudaSuccess;\n",
            "\n",
            "    // Print the vector length to be used, and compute its size\n",
            "    int numElements = 50000;\n",
            "    size_t size = numElements * sizeof(float);\n",
            "    printf(\"[Vector addition of %d elements]\\n\", numElements);\n",
            "\n",
            "    // Allocate the host input vector A\n",
            "    float *h_A = (float *)malloc(size);\n",
            "\n",
            "    // Allocate the host input vector B\n",
            "    float *h_B = (float *)malloc(size);\n",
            "\n",
            "    // Allocate the host output vector C\n",
            "    float *h_C = (float *)malloc(size);\n",
            "\n",
            "    // Verify that allocations succeeded\n",
            "    if (h_A == NULL || h_B == NULL || h_C == NULL)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to allocate host vectors!\\n\");\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    // Initialize the host input vectors\n",
            "    for (int i = 0; i < numElements; ++i)\n",
            "    {\n",
            "        h_A[i] = rand()/(float)RAND_MAX;\n",
            "        h_B[i] = rand()/(float)RAND_MAX;\n",
            "    }\n",
            "\n",
            "    // Allocate the device input vector A\n",
            "    float *d_A = NULL;\n",
            "    err = cudaMalloc((void **)&d_A, size);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to allocate device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    // Allocate the device input vector B\n",
            "    float *d_B = NULL;\n",
            "    err = cudaMalloc((void **)&d_B, size);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to allocate device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    // Allocate the device output vector C\n",
            "    float *d_C = NULL;\n",
            "    err = cudaMalloc((void **)&d_C, size);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to allocate device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    // Copy the host input vectors A and B in host memory to the device input vectors in\n",
            "    // device memory\n",
            "    printf(\"Copy input data from the host memory to the CUDA device\\n\");\n",
            "    err = cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to copy vector A from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    err = cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to copy vector B from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    // Launch the Vector Add CUDA Kernel\n",
            "    int threadsPerBlock = 256;\n",
            "    int blocksPerGrid =(numElements + threadsPerBlock - 1) / threadsPerBlock;\n",
            "    printf(\"CUDA kernel launch with %d blocks of %d threads\\n\", blocksPerGrid, threadsPerBlock);\n",
            "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, numElements);\n",
            "    err = cudaGetLastError();\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to launch vectorAdd kernel (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    // Copy the device result vector in device memory to the host result vector\n",
            "    // in host memory.\n",
            "    printf(\"Copy output data from the CUDA device to the host memory\\n\");\n",
            "    err = cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to copy vector C from device to host (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    // Verify that the result vector is correct\n",
            "    for (int i = 0; i < numElements; ++i)\n",
            "    {\n",
            "        if (fabs(h_A[i] + h_B[i] - h_C[i]) > 1e-5)\n",
            "        {\n",
            "            fprintf(stderr, \"Result verification failed at element %d!\\n\", i);\n",
            "            exit(EXIT_FAILURE);\n",
            "        }\n",
            "    }\n",
            "\n",
            "    printf(\"Test PASSED\\n\");\n",
            "\n",
            "    // Free device global memory\n",
            "    err = cudaFree(d_A);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to free device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    err = cudaFree(d_B);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to free device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    err = cudaFree(d_C);\n",
            "\n",
            "    if (err != cudaSuccess)\n",
            "    {\n",
            "        fprintf(stderr, \"Failed to free device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
            "        exit(EXIT_FAILURE);\n",
            "    }\n",
            "\n",
            "    // Free host memory\n",
            "    free(h_A);\n",
            "    free(h_B);\n",
            "    free(h_C);\n",
            "\n",
            "    printf(\"Done\\n\");\n",
            "    return 0;\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5cpHJOyllrMt",
        "colab_type": "code",
        "outputId": "194c81cd-d119-4918-9d82-8e38ea938fe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"*** browse location of all header files used for cuda samples ***\")\n",
        "!ls /usr/local/cuda-9.2/samples/common/inc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** browse location of all header files used for cuda samples ***\n",
            "cuda_drvapi_dynlink.c  helper_gl.h\t nvVector.h\n",
            "drvapi_error_string.h  helper_image.h\t paramgl.h\n",
            "dynlink\t\t       helper_math.h\t param.h\n",
            "dynlink_d3d10.h        helper_string.h\t rendercheck_d3d10.h\n",
            "dynlink_d3d11.h        helper_timer.h\t rendercheck_d3d11.h\n",
            "exception.h\t       multithreading.h  rendercheck_d3d9.h\n",
            "GL\t\t       nvMath.h\t\t rendercheck_gles.h\n",
            "helper_cuda_drvapi.h   nvMatrix.h\t rendercheck_gl.h\n",
            "helper_cuda.h\t       nvQuaternion.h\t timer.h\n",
            "helper_cusolver.h      nvrtc_helper.h\n",
            "helper_functions.h     nvShaderUtils.h\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PZys8KvyztkW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create our workingSpace"
      ]
    },
    {
      "metadata": {
        "id": "CxbL7QJnz7qc",
        "colab_type": "code",
        "outputId": "57a3be4e-b8ad-4967-b1df-e71a11cf6994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"*** make cuda workspace folder ***\")\n",
        "!mkdir CUDA_Workspace\n",
        "\n",
        "print(\"\\n*** copying vector add sample to our  workspace folder ***\")\n",
        "!cp -r /usr/local/cuda-9.2/samples/0_Simple/vectorAdd/ /content/CUDA_Workspace/vectorAdd\n",
        "\n",
        "print(\"\\n*** cd to the workspace folder ***\")\n",
        "%cd  CUDA_Workspace/vectorAdd\n",
        "\n",
        "!pwd\n",
        "!ls \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** make cuda workspace folder ***\n",
            "\n",
            "*** copying vector add sample to our  workspace folder ***\n",
            "\n",
            "*** cd to the workspace folder ***\n",
            "/content/CUDA_Workspace/vectorAdd\n",
            "Makefile  NsightEclipse.xml  readme.txt  vectorAdd.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cSvhfeoe2itI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compile vectorAdd sample"
      ]
    },
    {
      "metadata": {
        "id": "4bmRBDKmtLuH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#compile cuda code\n",
        "!/usr/local/cuda-9.2/bin/nvcc -I /usr/local/cuda-9.2/samples/common/inc vectorAdd.cu -o vectorAddCuda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ReRs4aQunju",
        "colab_type": "code",
        "outputId": "e0d731a0-c987-4bf8-97f9-a8ccd6cf39b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "#run cuda output\n",
        "!./vectorAddCuda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Vector addition of 50000 elements]\n",
            "Copy input data from the host memory to the CUDA device\n",
            "CUDA kernel launch with 196 blocks of 256 threads\n",
            "Copy output data from the CUDA device to the host memory\n",
            "Test PASSED\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jC756o7w7oc0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Upload from local machine"
      ]
    },
    {
      "metadata": {
        "id": "NV6LsGUy743h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#upload file from local machine\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "def uploadFile(fname):\n",
        "\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  ##files.upload returns a dictionary of the files which were uploaded. The \n",
        "  ##dictionary is keyed by the file name, the value is the data which was \n",
        "  ##uploaded.\n",
        "  #fileContent=\"\"\n",
        "  for fn in uploaded.keys():\n",
        "    print(fn,len(uploaded[fn]))\n",
        "    print(uploaded[fn],\"___\") \n",
        "\n",
        "    \n",
        "    #fileContent= uploaded[fn]\n",
        "    #saveFile(fn,fileContent.decode(\"utf-8\"))\n",
        "    break\n",
        "  return uploaded[fname]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m5kYvKOa8A3D",
        "colab_type": "code",
        "outputId": "6287b270-576b-4b08-a7cd-cc4b067d6b84",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "cell_type": "code",
      "source": [
        "%cd CUDA_Workspace/sample2/\n",
        "#!mkdir sample2\n",
        "!pwd\n",
        "#%cd sample2\n",
        "outString= uploadFile('add.cpp')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CUDA_Workspace/sample2\n",
            "/content/CUDA_Workspace/sample2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-68952b09-934b-46aa-9743-4fc6aa437ae3\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-68952b09-934b-46aa-9743-4fc6aa437ae3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving add.cpp to add.cpp\n",
            "add.cpp 817\n",
            "b'#include <iostream>\\r\\n#include <math.h>\\r\\n\\r\\n// function to add the elements of two arrays\\r\\nvoid add(int n, float *x, float *y)\\r\\n{\\r\\n  for (int i = 0; i < n; i++)\\r\\n      y[i] = x[i] + y[i];\\r\\n}\\r\\n\\r\\nint main(void)\\r\\n{\\r\\n  int N = 1<<20; // 1M elements\\r\\n\\r\\n  float *x = new float[N];\\r\\n  float *y = new float[N];\\r\\n\\r\\n  // initialize x and y arrays on the host\\r\\n  for (int i = 0; i < N; i++) {\\r\\n    x[i] = 1.0f;\\r\\n    y[i] = 2.0f;\\r\\n  }\\r\\n\\r\\n  // Run kernel on 1M elements on the CPU\\r\\n  add(N, x, y);\\r\\n\\r\\n  // Check for errors (all values should be 3.0f)\\r\\n  float maxError = 0.0f;\\r\\n  for (int i = 0; i < N; i++)\\r\\n    //std::cout << i<<\": \" << y[i] << std::endl;\\r\\n    maxError = fmax(maxError, fabs(y[i]-3.0f));\\r\\n  std::cout << \"Max error: \" << maxError << std::endl;\\r\\n\\r\\n  // Free memory\\r\\n  delete [] x;\\r\\n  delete [] y;\\r\\n\\r\\n  return 0;\\r\\n}' ___\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aoODjMsXHhrr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!rm CUDA_Workspace/sample2/addSerial\n",
        "#!ls\n",
        "!g++ 'add.cpp' -o addSerial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QVpmRgh-9IC_",
        "colab_type": "code",
        "outputId": "ff23c6ab-0d23-4117-8767-d59b17169309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "cell_type": "code",
      "source": [
        "!cat add.cpp"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#include <iostream>\r\n",
            "#include <math.h>\r\n",
            "\r\n",
            "// function to add the elements of two arrays\r\n",
            "void add(int n, float *x, float *y)\r\n",
            "{\r\n",
            "  for (int i = 0; i < n; i++)\r\n",
            "      y[i] = x[i] + y[i];\r\n",
            "}\r\n",
            "\r\n",
            "int main(void)\r\n",
            "{\r\n",
            "  int N = 1<<20; // 1M elements\r\n",
            "\r\n",
            "  float *x = new float[N];\r\n",
            "  float *y = new float[N];\r\n",
            "\r\n",
            "  // initialize x and y arrays on the host\r\n",
            "  for (int i = 0; i < N; i++) {\r\n",
            "    x[i] = 1.0f;\r\n",
            "    y[i] = 2.0f;\r\n",
            "  }\r\n",
            "\r\n",
            "  // Run kernel on 1M elements on the CPU\r\n",
            "  add(N, x, y);\r\n",
            "\r\n",
            "  // Check for errors (all values should be 3.0f)\r\n",
            "  float maxError = 0.0f;\r\n",
            "  for (int i = 0; i < N; i++)\r\n",
            "    //std::cout << i<<\": \" << y[i] << std::endl;\r\n",
            "    maxError = fmax(maxError, fabs(y[i]-3.0f));\r\n",
            "  std::cout << \"Max error: \" << maxError << std::endl;\r\n",
            "\r\n",
            "  // Free memory\r\n",
            "  delete [] x;\r\n",
            "  delete [] y;\r\n",
            "\r\n",
            "  return 0;\r\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AVQEp_8H9r5Y",
        "colab_type": "code",
        "outputId": "8528462a-609c-4f98-fb9e-204027ef1b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!./addSerial"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max error: 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}